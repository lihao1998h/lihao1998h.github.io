<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/fluid.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-test" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/47c93aa5802a.html" class="article-date">
  <time datetime="2023-02-11T09:58:37.478Z" itemprop="datePublished">2023-02-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <hr>
<p>标题：test<br>日期：2023-02-11<br>分类：<br>标签：666</p>
<hr>
<p>aaaaa</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/47c93aa5802a.html" data-id="cldzsk2960000d8nc7mesgeg8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计算机视觉/通用模块/多尺度特征融合" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/57a6e32ff281.html" class="article-date">
  <time datetime="2023-02-11T09:45:54.885Z" itemprop="datePublished">2023-02-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
  </div>

  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="U-Net结构"><a href="#U-Net结构" class="headerlink" title="U-Net结构"></a>U-Net结构</h1><p>upsample+add</p>
<h1 id="特征金字塔结构"><a href="#特征金字塔结构" class="headerlink" title="特征金字塔结构"></a>特征金字塔结构</h1><p>![[Pasted image 20230127135716.png]]</p>
<p>融合后通常要再加个3*3卷积</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/57a6e32ff281.html" data-id="cldzsk2am0038d8ncalmv49ch" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计算机视觉/语义分割/数据集/数据集" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/e306f9f8860c.html" class="article-date">
  <time datetime="2023-02-11T09:45:54.880Z" itemprop="datePublished">2023-02-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
  </div>

  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h1><p>[[VOC12]]：有 20 类目标，这些目标包括人类、机动车类以及其他类，可用于目标类别或背景的分割</p>
<p>MSCOCO：是一个新的图像识别、分割和图像语义数据集，是一个大规模的图像识别、分割、标注数据集。它可以用于多种竞赛，与本领域最相关的是检测部分，因为其一部分是致力于解决分割问题的。该竞赛包含了超过80个物体类别</p>
<p>Cityscapes ：50 个城市的城市场景语义理解数据集</p>
<p>Stanford Background Dataset：至少有一个前景物体的一组户外场景。</p>
<p>Pascal Context：有 400 多类的室内和室外场景</p>
<h1 id="增量专用"><a href="#增量专用" class="headerlink" title="增量专用"></a>增量专用</h1><h2 id="增量小样本专用"><a href="#增量小样本专用" class="headerlink" title="增量小样本专用"></a>增量小样本专用</h2><p>[[Pascal-5i]]</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/e306f9f8860c.html" data-id="cldzsk2aw004cd8nc1aa5gbcp" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计算机视觉/语义分割/数据集/VOC12_aug" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/d42e9f60b4b0.html" class="article-date">
  <time datetime="2023-02-11T09:45:54.879Z" itemprop="datePublished">2023-02-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
  </div>

  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>PASCAL VOC 2012 增强数据集（PASCAL VOC 2012 Augmented Dataset）是目前语义分割和实例分割领域最常用、也是最基础的 benchmark 数据集，它是由VOC2012和SBD合二为一制作的，下面只针对分割任务进行说明：</p>
<p>PASCAL VOC 2012：用于分割任务中训练+验证的图像有 2913 张，用于测试的图像有 1456 张<br>Semantic Boundaries Dataset（SBD）：用于训练和验证分别有 8498 张和 2857 张<br>![[Pasted image 20221221203459.png]]<br>| 数据集 | 训练+验证（trainval） | 测试（test） | 类别数 |<br>| —— | ——————— | ———— | —— |<br>|PASCAL VOC 2012    |2913|    1456|    21<br>|SBD    |11355    |/    |21<br>|PASCAL VOC 2012 Augmented Dataset    |12031|    1456|    21|</p>
<p>下载地址： <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_31347869/article/details/93742029/">https://blog.csdn.net/qq_31347869/article/details/93742029/</a></p>
<h1 id="download-bash"><a href="#download-bash" class="headerlink" title="download bash"></a>download bash</h1><p>wget <a target="_blank" rel="noopener" href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar">http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar</a><br>tar -xf VOCtrainval_11-May-2012.tar<br>mkdir PascalVOC12<br>mv VOCdevkit/VOC2012/* PascalVOC12<br>cd PascalVOC12</p>
<p>wget <a target="_blank" rel="noopener" href="http://cs.jhu.edu/~cxliu/data/SegmentationClassAug.zip">http://cs.jhu.edu/~cxliu/data/SegmentationClassAug.zip</a><br>wget <a target="_blank" rel="noopener" href="http://cs.jhu.edu/~cxliu/data/SegmentationClassAug_Visualization.zip">http://cs.jhu.edu/~cxliu/data/SegmentationClassAug_Visualization.zip</a><br>wget <a target="_blank" rel="noopener" href="http://cs.jhu.edu/~cxliu/data/list.zip">http://cs.jhu.edu/~cxliu/data/list.zip</a><br>unzip SegmentationClassAug.zip<br>unzip SegmentationClassAug_Visualization.zip<br>unzip list.zip</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/d42e9f60b4b0.html" data-id="cldzsk2av0044d8nchp5n3v63" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计算机视觉/语义分割/数据集/VOC12" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/7411c7521421.html" class="article-date">
  <time datetime="2023-02-11T09:45:54.877Z" itemprop="datePublished">2023-02-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
  </div>

  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="基本描述"><a href="#基本描述" class="headerlink" title="基本描述"></a>基本描述</h1><p>包括二十个对象类别：</p>
<p>Person ：person<br>Animal ：bird, cat, cow, dog, horse, sheep<br>Vehicle ：aeroplane, bicycle, boat, bus, car, motorbike, train<br>Indoor ：bottle, chair, dining table, potted plant, sofa, tv/monitor</p>
<p>有三个主要的对象识别竞赛：<strong>分类</strong> 、<strong>检测</strong> 和 <strong>分割</strong></p>
<h1 id="文件夹介绍"><a href="#文件夹介绍" class="headerlink" title="文件夹介绍"></a>文件夹介绍</h1><p>VOC 2012 文件夹下一共包括 5 个子文件夹：</p>
<ul>
<li>Annotations：图像信息</li>
<li>ImageSets：四类子数据集</li>
<li>JPEGImages：训练集和测试集一共 17125 张</li>
<li>SegmentationClass：语义分割标注掩模图</li>
<li>SegmentationObject：实例分割标注掩模图<h1 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h1><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_39435411/article/details/127132007">https://blog.csdn.net/qq_39435411/article/details/127132007</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/7411c7521421.html" data-id="cldzsk2au0042d8nc5fej16jt" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计算机视觉/语义分割/数据集/Pascal-5i" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/5d5df8bfb08a.html" class="article-date">
  <time datetime="2023-02-11T09:45:54.875Z" itemprop="datePublished">2023-02-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
  </div>

  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://paperswithcode.com/dataset/pascal-5i">https://paperswithcode.com/dataset/pascal-5i</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/DeepTrial/pascal-5">https://github.com/DeepTrial/pascal-5</a> 官方实现有bug</p>
<p>用于小样本分割任务</p>
<p>20个类，分为四组，每组包含5类，3组训练，1组测试小样本分割性能。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/5d5df8bfb08a.html" data-id="cldzsk2au0040d8nc8grahue3" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计算机视觉/语义分割/小样本分割/小样本分割" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/bba7f7dc3ec9.html" class="article-date">
  <time datetime="2023-02-11T09:45:54.872Z" itemprop="datePublished">2023-02-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
  </div>

  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>[[基于原型的小样本分割]]</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/bba7f7dc3ec9.html" data-id="cldzsk2at003yd8nc7svv6rij" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计算机视觉/语义分割/小样本分割/基于原型的小样本分割" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/5826699072d4.html" class="article-date">
  <time datetime="2023-02-11T09:45:54.870Z" itemprop="datePublished">2023-02-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
  </div>

  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-基本组件"><a href="#1-基本组件" class="headerlink" title="1 基本组件"></a>1 基本组件</h1><h2 id="1-1-masked-average-pooling"><a href="#1-1-masked-average-pooling" class="headerlink" title="1.1 masked average pooling"></a>1.1 masked average pooling</h2><p><strong>为什么 masked average pooling 会有用？</strong></p>
<p>解释如下：全卷积网络（FCN）能够保留输入图像的中每个像素相对位置；所以通过将二值 mask 与提取到的特征图相乘就可以完全保留目标的特征信息，排除掉背景等无关类别的特征。</p>
<h1 id="2-只分割一类的"><a href="#2-只分割一类的" class="headerlink" title="2 只分割一类的"></a>2 只分割一类的</h1><h2 id="2-1-Prototype-Mixture-Models-for-Few-shot-Semantic-Segmentation-（ECCV-2020）"><a href="#2-1-Prototype-Mixture-Models-for-Few-shot-Semantic-Segmentation-（ECCV-2020）" class="headerlink" title="2.1 Prototype Mixture Models for Few-shot Semantic Segmentation （ECCV 2020）"></a>2.1 Prototype Mixture Models for Few-shot Semantic Segmentation （ECCV 2020）</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/508912133">解读</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2008.03898.pdf">论文</a><br><a target="_blank" rel="noopener" href="https://github.com/Yang-Bob/PMMs">代码</a><br>![[Pasted image 20221217170608.png]]</p>
<h2 id="2-2-CANet-CVPR-2019"><a href="#2-2-CANet-CVPR-2019" class="headerlink" title="2.2 CANet (CVPR 2019)"></a>2.2 CANet (CVPR 2019)</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1903.02351">论文</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_41997920/article/details/96307267">解读</a><br><a target="_blank" rel="noopener" href="https://github.com/icoz69/CaNet">代码</a></p>
<p>接几个残差就是迭代了？</p>
<h2 id="2-3-SG-One-（IEEE-Transactions-on-Cybernetics-2020）"><a href="#2-3-SG-One-（IEEE-Transactions-on-Cybernetics-2020）" class="headerlink" title="2.3 SG-One （IEEE Transactions on Cybernetics 2020）"></a>2.3 SG-One （IEEE Transactions on Cybernetics 2020）</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.09091">论文</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38932073/article/details/115305005">解读</a><br><a target="_blank" rel="noopener" href="https://github.com/xiaomengyc/SG-One">代码</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_38974831/article/details/125996880">https://blog.csdn.net/sinat_38974831/article/details/125996880</a></p>
<h1 id="3-同时分割许多类的"><a href="#3-同时分割许多类的" class="headerlink" title="3 同时分割许多类的"></a>3 同时分割许多类的</h1><p>增量分割不得同时分割许多类吗！</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/5826699072d4.html" data-id="cldzsk2at003wd8ncdsl64o54" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计算机视觉/语义分割/增量分割/增量分割" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/95ffeaff2677.html" class="article-date">
  <time datetime="2023-02-11T09:45:54.866Z" itemprop="datePublished">2023-02-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
  </div>

  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-PLOP-2021CVPR"><a href="#1-PLOP-2021CVPR" class="headerlink" title="1 PLOP 2021CVPR"></a>1 PLOP 2021CVPR</h1><p>![[PLOP,CVPR2021.pdf]]<br><a target="_blank" rel="noopener" href="https://github.com/arthurdouillard/CVPR2021_PLOP">code</a>:基于MiB</p>
<h1 id="2-MiB-2020CVPR"><a href="#2-MiB-2020CVPR" class="headerlink" title="2 MiB 2020CVPR"></a>2 MiB 2020CVPR</h1><p>![[Cermelli_Modeling_the_Background_for_Incremental_Learning_in_Semantic_Segmentation_CVPR_2020_paper.pdf]]</p>
<p><a target="_blank" rel="noopener" href="https://github.com/fcdl94/MiB">code</a></p>
<h1 id="3-小样本增量分割"><a href="#3-小样本增量分割" class="headerlink" title="3 小样本增量分割"></a>3 小样本增量分割</h1><h2 id="3-1-师兄的-2022ACM-MM"><a href="#3-1-师兄的-2022ACM-MM" class="headerlink" title="3.1 师兄的 2022ACM MM"></a>3.1 师兄的 2022ACM MM</h2><p>![[sigconf ACM MM2022.pdf]]</p>
<p>![[Pasted image 20221217170857.png]]</p>
<p>迭代优化来自于CANet [[基于原型的小样本分割#1.2 CANet (CVPR 2019)]]</p>
<h2 id="3-2-nobody"><a href="#3-2-nobody" class="headerlink" title="3.2 nobody"></a>3.2 nobody</h2><p>![[2012.01415v2.pdf]]</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/95ffeaff2677.html" data-id="cldzsk2as003ud8nc6mi1ez5f" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-计算机视觉/语义分割/增量分割/(new work)基于因果推理的增量小样本图像分割" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2023/02/34f40f5b951a.html" class="article-date">
  <time datetime="2023-02-11T09:45:54.865Z" itemprop="datePublished">2023-02-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
  </div>

  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-ideas"><a href="#1-ideas" class="headerlink" title="1 ideas"></a>1 ideas</h1><p>idea确定时间：2022.9.30<br>![[pptv1.pptx]]<br>![[pptv2.pptx]]<br>![[pptv3.pptx]]<br>![[pptv3-2.pptx]]<br>![[pptv4.pptx]]<br>![[wordv1.docx]]<br>![[wordv2.docx]]<br>![[pptv5.pptx]]<br>![[wordv3.docx]]</p>
<h1 id="2-introduction"><a href="#2-introduction" class="headerlink" title="2 introduction"></a>2 introduction</h1><p>图像分割是计算机视觉的基本问题。现有图像分割方法基于CNN对训练数据集提供的类别能够很好的分割 [cites]。 但在一个更现实的场景，即Class Incremental Semantic Segmentation (CI-SS)，模型应当能够只根据新数据连续的学习新类，而不是重新训练整个模型。<br>增量图像分割目前受到少量的关注，其主要原因是其面临着两大挑战，即灾难性遗忘和语义漂移。灾难性遗忘指的是模型在学习新知识时会遗忘过去学到的知识[1]。语义漂移指的是背景类的语义随着时间会发生改变，这包含两方面含义，一方面指的是旧任务的背景类中可能包含新任务或未来任务中要学习的类，另一方面指的是新任务中的背景类可能包含旧任务中已经学习过的类。为此，许多研究[2-7]引入了知识蒸馏的方法来缓解灾难性遗忘，还有少量研究[8-9]通过构造伪标签来缓解语义漂移问题。<br>    然而，现有的增量图像分割方法往往要求新任务具有大量的训练数据，当其样本量少的时候性能急剧下降（需要实验证明），这是因为用小样本训练的模型很容易陷入对小样本的过拟合以及对新类语义的不完全学习。<br>    在本文中，我们将小样本增量图像分割构建为一个因果推理框架来主动解决上面提到的问题，该框架对新类、旧类、背景类及最终输出结果的因果关系进行建模，通过构建新类与旧类关联来解决语义不完全问题，并通过干预切断背景类与旧类之间的联系来解决语义漂移问题，具体来说，我们引入了原型学习保留旧类知识以缓解语义不完全问题，为了能够用少量新类样本学习完全的新类语义，我们需要借助旧类知识，对新类语义进行补全。不仅如此，我们通过因果推理中的前门调整公式，切断了背景类与旧类之间的联系，从而避免了模型对旧类的错误分割。</p>
<pre><code>我们的贡献可总结为：
</code></pre>
<p>1、我们为小样本增量图像分割构建了一个因果推理框架，通过构建新类与旧类的依赖预测来解决不完全语义问题，并通过切断背景类与旧类之间的联系来解决语义漂移问题。</p>
<p>2、我们提出了一个原型修正模块，可以利用旧类知识来修正语义不完全的新类原型，以解决小样本场景导致的过拟合问题。</p>
<p>3、我们设计了一个旧类干预模块，通过因果推理中的前门调整公式约束了模型对旧类的错误分割，从而避免了语义漂移问题。</p>
<h1 id="3-related-work"><a href="#3-related-work" class="headerlink" title="3 related work"></a>3 related work</h1><p>[[语义分割]]<br>[[增量分割]]<br>[[基于原型的小样本分类]]</p>
<h1 id="4-代码逻辑"><a href="#4-代码逻辑" class="headerlink" title="4 代码逻辑"></a>4 代码逻辑</h1><p>以VOC12 task：19-1为例</p>
<h2 id="4-1-数据集的处理"><a href="#4-1-数据集的处理" class="headerlink" title="4.1 数据集的处理"></a>4.1 数据集的处理</h2><p>训练集和验证集使用官方[[VOC12_aug]]提供的划分</p>
<pre><code>筛选
</code></pre>
<p>overlap<br>存在类是当前训练的新类即可，但未来类的mask被强制设置为0，即背景</p>
<p>disjoint<br>存在类是当前训练的新类，且所有类都得是学过的类或者是0和255（避免了出现未来类的可能）</p>
<pre><code>测试集的设置
</code></pre>
<p>一种策略是test_on_val，即按比例从验证集中划出一部分作为测试集<br>另一种</p>
<h2 id="4-2-预训练（要不要，实验说话）"><a href="#4-2-预训练（要不要，实验说话）" class="headerlink" title="4.2 预训练（要不要，实验说话）"></a>4.2 预训练（要不要，实验说话）</h2><p>目的：获得好的初始backbone和head</p>
<p>输入的处理：输入为单类的图像和mask还有classid（不在论文中展示）</p>
<p>以VOC12为例，20个类<br>task:19-1</p>
<p>如果是补全的代码就是19个类train，1个类val<br>合理的做法应该是19个类train也在这19个类上val</p>
<p>训练集：19 train<br>验证集 19 val<br>test：19val</p>
<p>步骤：<br>1、通过backbone提取图像特征<br>2、然后通过map提取各类原型向量并扩展到特征图的大小，<br>3、与特征融合输入head。</p>
<p>batchsize=8，epoch=100，lr=0.007，polylr</p>
<p>论文中：写的是一个proto一个预测一个类后合并结果，而实验中简化，数据预处理为单类mask</p>
<h2 id="4-3-learn-base"><a href="#4-3-learn-base" class="headerlink" title="4.3 learn_base"></a>4.3 learn_base</h2><p>目的：学习基类，测试基类性能，并保留基类原型向量<br>1、读取预训练的backbone和head</p>
<h2 id="4-4-meta-train"><a href="#4-4-meta-train" class="headerlink" title="4.4 meta train"></a>4.4 meta train</h2><p>目的：元训练获得原型修正模块</p>
<p>2、提取并保存各类的原型向量（类的所有原型向量取平均）（todo模仿）<br>3、构造小样本增量分割元episode</p>
<p>接着构造episode<br>todo：</p>
<ul>
<li>融合各类输出</li>
<li>保存原型向量<h2 id="4-5-step-0"><a href="#4-5-step-0" class="headerlink" title="4.5 step 0"></a>4.5 step 0</h2>训练集：19 train<br>验证集 19 val<br>test：19val</li>
</ul>
<p>使用预训练的backbone和head为初始值</p>
<p>接着通过MAP提取原型向量，并输入到分割头输出结果，保留各类原型向量。</p>
<h2 id="4-6-step-1"><a href="#4-6-step-1" class="headerlink" title="4.6 step 1"></a>4.6 step 1</h2><h3 id="4-6-1-step-1-without-incremental"><a href="#4-6-1-step-1-without-incremental" class="headerlink" title="4.6.1 step 1 without incremental"></a>4.6.1 step 1 without incremental</h3><h3 id="4-6-2-step-1-with-few-shot-with-incremental"><a href="#4-6-2-step-1-with-few-shot-with-incremental" class="headerlink" title="4.6.2 step 1 with few shot with incremental"></a>4.6.2 step 1 with few shot with incremental</h3><h3 id="4-6-3-step-1-with-many-shot-with-incremental"><a href="#4-6-3-step-1-with-many-shot-with-incremental" class="headerlink" title="4.6.3 step 1 with many shot with incremental"></a>4.6.3 step 1 with many shot with incremental</h3><h3 id="4-6-4-our-step1"><a href="#4-6-4-our-step1" class="headerlink" title="4.6.4 our step1"></a>4.6.4 our step1</h3><h1 id="5-experiments"><a href="#5-experiments" class="headerlink" title="5 experiments"></a>5 experiments</h1><h2 id="5-1-datasets"><a href="#5-1-datasets" class="headerlink" title="5.1 datasets"></a>5.1 datasets</h2><p>[[VOC12_aug]]<br>19-1 15-5 15-1-1-1-1-1</p>
<h2 id="5-2-our-model"><a href="#5-2-our-model" class="headerlink" title="5.2 our model"></a>5.2 our model</h2><p>body:resnet101 （todo 换）<br>输出维度2048</p>
<p>head：(ours) DeepLab_with_proto（todo 换）输入特征与原型融合</p>
<p>1、对比试验与各种增量分割方法在小样本情况比（在大样本也可以试试）  （相比师兄的论文，是从小样本分割-&gt;小样本增量分割）</p>
<p>todo：测试下不用while，因为filter已经做好了</p>
<h2 id="5-3-对比方法"><a href="#5-3-对比方法" class="headerlink" title="5.3 对比方法"></a>5.3 对比方法</h2><p>简单的fine-tune</p>
<p>各种增量方法用于分割 在小样本情况的劣势<br>小样本增量分割方法</p>
<p>增量数据联合训练</p>
<h2 id="5-4-metrics"><a href="#5-4-metrics" class="headerlink" title="5.4 metrics"></a>5.4 metrics</h2><p>overlap vs disjoint：overlap就是图像可能包含未来类但是标记为背景，disjoint则图像中不会出现未来要学习的类。<br>1、各step的mIoU<br>以voc12的19-1task来说，要输出step 0 即训练完19之后对19的mIoU，在训练完1之后既要输出19的mIoU(这个PLOP缺少)，也要输出1的mIoU。<br>2、all表示所有step训练完后的mIoU<br>3、average表示每个step训练之后mIoU的平均</p>
<h2 id="5-5-results"><a href="#5-5-results" class="headerlink" title="5.5 results"></a>5.5 results</h2><h3 id="5-5-1-pretrain"><a href="#5-5-1-pretrain" class="headerlink" title="5.5.1 pretrain"></a>5.5.1 pretrain</h3><p>epoch now=29</p>
<p>![[Pasted image 20230204122618.png|175]]</p>
<p>INFO:Validation, Class Loss=0.11368785798549652, Reg Loss=0.0 (without scaling)<br>INFO:Done validation<br>INFO:End of Validation 31/100, Validation Loss=0.11368785798549652, Class Loss=0.11368785798549652, Reg Loss=0.0<br>INFO:<br>Total samples: 711.000000<br>Overall Acc: 0.954122<br>Mean Acc: 0.940762<br>FreqW Acc: 0.914056<br>Mean IoU: 0.882133<br>Class IoU:<br>        class 0: 0.9417315489533514<br>        class 1: 0.8225347702348145<br>        class 2: X<br>        class 3: X<br>        class 4: X<br>        class 5: X<br>        class 6: X<br>        class 7: X<br>        class 8: X<br>        class 9: X<br>        class 10: X<br>        class 11: X<br>        class 12: X<br>        class 13: X<br>        class 14: X<br>        class 15: X<br>        class 16: X<br>        class 17: X<br>        class 18: X<br>        class 19: X<br>        class 20: X<br>Class Acc:<br>        class 0: 0.9657040220511824<br>        class 1: 0.9158207919453918<br>        class 2: X<br>        class 3: X<br>        class 4: X<br>        class 5: X<br>        class 6: X<br>        class 7: X<br>        class 8: X<br>        class 9: X<br>        class 10: X<br>        class 11: X<br>        class 12: X<br>        class 13: X<br>        class 14: X<br>        class 15: X<br>        class 16: X<br>        class 17: X<br>        class 18: X<br>        class 19: X<br>        class 20: X</p>
<h1 id="6-tricks"><a href="#6-tricks" class="headerlink" title="6 tricks"></a>6 tricks</h1><ol>
<li>预训练在验证集上验证 </li>
</ol>
<h1 id="7-bugs"><a href="#7-bugs" class="headerlink" title="7 bugs"></a>7 bugs</h1><ol>
<li>voc gt mask 有些全0或全0和255的直接跳过训练了</li>
</ol>
<h1 id="8-reference"><a href="#8-reference" class="headerlink" title="8 reference"></a>8 reference</h1><p>[1] Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist networks: The sequential learning problem. In Psychology of learning and motivation, volume 24, pages 109–165. Elsevier, 1989.</p>
<p>[2] Gu, et al. Class-Incremental Instance Segmentation via Multi-Teacher Networks. AAAI, 2021.</p>
<p>[3] Umberto Michieli and Pietro Zanuttigh. 2021. Knowledge distillation for incremental learning in semantic segmentation. Comput. Vis. Image Underst. 205 (2021), 103167</p>
<p>[4] Firat Ozdemir, Philipp Fuernstahl, and Orcun Goksel. 2018. Learn the new, keep the old: Extending pretrained models with new anatomy and images. In International Conference on Medical Image Computing and Computer-Assisted Intervention(MICCAI).</p>
<p>[5] A Contrastive Distillation Approach for Incremental Semantic Segmentation in Aerial Images. ICIAP 2021</p>
<p>[6]Representation Compensation Networks for Continual Semantic Segmentation. CVPR 2022 改进PLOP的蒸馏和结构化重参</p>
<p>[7]Class Similarity Weighted Knowledge Distillation for Continual Semantic Segmentation. CVPR 2022 改进的蒸馏，考虑了与新类最相似的旧类，提醒不要忘了最相似的旧类</p>
<p>[8] Douillard, et al. PLOP: Learning without Forgetting for Continual Semantic Segmentation. CVPR, 2021.</p>
<p>[9] Cermelli, et al. Modeling the Background for Incremental Learning in Semantic Segmentation. CVPR, 2020.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/34f40f5b951a.html" data-id="cldzsk2as003sd8nc4dnn3ajl" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/">下一页 &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">二月 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/02/47c93aa5802a.html">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/02/57a6e32ff281.html">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/02/e306f9f8860c.html">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/02/d42e9f60b4b0.html">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/02/7411c7521421.html">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>